{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of Machine Learning Algorithms  \n",
    "\n",
    "## SUPERVISED LEARNING ALGORITHMS: \n",
    "\n",
    "1. **Logistic Regression** : Logistic regression is a statistical method that is used for building machine learning models where the dependent variable is dichotomous: i.e. binary.Logistic regression is used to describe data and the relationship between one dependent variable and one or more independent variables(can be nominal, ordinal, or of interval type).\n",
    "   \n",
    "2. **K-Nearest Neighbors(K-NN)**: A machine learning supervised type instance-based algorithm that can be used to classify new samples (discrete values) or to predict (regression, continuous values). Being a simple method, it is ideal to enter the world of Machine Learning. It essentially serves to classify values ​by looking for the “most similar” data points (by closeness) learned in the training stage ( see 7 steps to create your ML ) and making guesses of new points based on that classification.\n",
    "   \n",
    "3. **Support Vector Machine(SVM)**: Most popular supervised learning algorithm, which is used for classification as well as regression problems. In the SVM algorithm, we plot each data item as a point in n-dimensional space (where n is a number of features you have) with the value of each feature being the value of a particular coordinate. Then, we perform classification by finding the hyper-plane that differentiates the two classes very well.\n",
    "   \n",
    "4. **Kernel SVM**: In case of non-linearly separable data, the simple SVM algorithm cannot be used. Rather, a modified version of SVM, called Kernel SVM, is used. Basically, the kernel SVM projects the non-linearly separable data lower dimensions to linearly separable data in higher dimensions in such a way that data points belonging to different classes are allocated to different dimensions.\n",
    "   \n",
    "5. **Naive Bayes**: Naive Bayes classifiers are a collection of classification algorithms based on Bayes’ Theorem. It is not a single algorithm but a family of algorithms where all of them share a common principle, i.e. every pair of features being classified is independent of each other.\n",
    "   \n",
    "6. **Decision Tree Classification**: A Decision Tree is a simple representation for classifying examples. It is a Supervised Machine Learning where the data is continuously split according to a certain parameter.\n",
    "   \n",
    "7. **Random Forest Classification**: A random forest is a machine learning technique that’s used to solve regression and classification problems. It utilizes ensemble learning, which is a technique that combines many classifiers to provide solutions to complex problems. The (random forest) algorithm establishes the outcome based on the predictions of the decision trees. It predicts by taking the average or mean of the output from various trees. Increasing the number of trees increases the precision of the outcome.\n",
    "\n",
    "## UNSUPERVISED LEARNING ALGORITHMS: \n",
    "\n",
    "* **K-Means Clustering**:The k-means clustering method is an unsupervised machine learning technique used to identify clusters of data objects in a dataset. There are many different types of clustering methods, but k-means is one of the oldest and most approachable. These traits make implementing k-means clustering in Python reasonably straightforward, even for novice programmers and data scientists.\n",
    "* **Hierarchical Clustering**: Hierarchical clustering is a type of unsupervised machine learning algorithm used to cluster unlabeled data points. Like K-means clustering, hierarchical clustering also groups together the data points with similar characteristics. In some cases the result of hierarchical and K-Means clustering can be similar.\n",
    "* **Probabilistic Clustering**: In probabilistic clustering the assignment of points to clusters is “soft”, in the sense that the membership of a data point x in a cluster Ck is given as a probability, denoted by pk(x). These are subjective probabilities, indicating strength of belief in the event in question.\n",
    "  \n",
    "## REINFORCEMENT LEARNING ALGORITHMS: \n",
    "\n",
    "1. **Model-Free Reinforcement Learning**:All model free learning algorithms learn value functions directly from the environment.These models focus on figuring out the value functions directly from the interactions with the environment\n",
    "   -  **Policy Optimization**:Policy optimization methods are centered around the policy, the function that maps the agent's state to its next action. These methods view reinforcement learning as a numerical optimization problem where we optimize the expected reward with respect to the policy's parameters.\n",
    "   -  **u-Learning**:U-learning is characterized by accessibility where the information is readily available whenever learners need its utilization. In u-learning the information remains on the platform and is always available to learners. \n",
    "  \n",
    "2. **Model-Based Reinforcement Learning**:Model-based Reinforcement Learning refers to learning optimal behavior indirectly by learning a model of the environment by taking actions and observing the outcomes that include the next state and the immediate reward.\n",
    "   -  **Learn the Model**\n",
    "   -  **Given the Model** "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5c0f63f8d85341b9844318c0f50c2d88d5a3002c1cf10952ef83f9b0f990ca8d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
